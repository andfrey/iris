{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f5b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import sys\n",
    "from typing import Optional, Iterable, Union\n",
    "import h5py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.measure import regionprops, label\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy import ndimage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e098742",
   "metadata": {},
   "source": [
    "### Source the cell images and extract some features (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51728d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nuclei_cell_features(image: np.ndarray, mask: np.ndarray, cell_name: str) -> pd.DataFrame:\n",
    "    # Label connected regions in the mask\n",
    "    labeled_mask = label(mask)\n",
    "\n",
    "    # Extract properties for each cell region\n",
    "    properties = regionprops(labeled_mask, intensity_image=image)\n",
    "\n",
    "    feat_dict = {}\n",
    "    \n",
    "    feat_dict['label'] = properties[0].label\n",
    "    feat_dict['area'] = properties[0].area\n",
    "    feat_dict['perimeter'] = properties[0].perimeter\n",
    "    feat_dict['mean_intensity'] = properties[0].mean_intensity\n",
    "    feat_dict['eccentricity'] = properties[0].eccentricity\n",
    "    feat_dict['solidity'] = properties[0].solidity\n",
    "    feat_dict['extent'] = properties[0].extent\n",
    "    feat_dict['major_axis_length'] = properties[0].major_axis_length\n",
    "    feat_dict['minor_axis_length'] = properties[0].minor_axis_length\n",
    "    feat_dict['cell_name'] = cell_name\n",
    "    # Calculate total intensity inside and outside the mask\n",
    "    total_intensity_inside = np.sum(image[mask > 0])\n",
    "    total_intensity_outside = np.sum(image[mask == 0])\n",
    "    total_intensity = total_intensity_inside + total_intensity_outside\n",
    "\n",
    "    # Calculate the ratio of energy outside vs inside\n",
    "    if total_intensity > 0:\n",
    "        feat_dict['intensity_inside'] = total_intensity_inside\n",
    "        feat_dict['intensity_outside'] = total_intensity_outside\n",
    "        feat_dict['intensity_ratio_outside_inside'] = total_intensity_outside / total_intensity_inside if total_intensity_inside > 0 else np.inf\n",
    "        feat_dict['intensity_fraction_outside'] = total_intensity_outside / total_intensity\n",
    "    else:\n",
    "        feat_dict['intensity_inside'] = 0\n",
    "        feat_dict['intensity_outside'] = 0\n",
    "        feat_dict['intensity_ratio_outside_inside'] = 0\n",
    "        feat_dict['intensity_fraction_outside'] = 0\n",
    "    return feat_dict    \n",
    "\n",
    "def normalize_and_filter_image(image: np.ndarray, apply_gaussian: bool = True, sigma: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalisiert das Bild und wendet optional einen Gauss-Filter an\n",
    "    \n",
    "    Args:\n",
    "        image: Input image array\n",
    "        apply_gaussian: Whether to apply Gaussian filter\n",
    "        sigma: Standard deviation for Gaussian filter\n",
    "    \"\"\"\n",
    "    # Optional: Gauss-Filter anwenden\n",
    "    if apply_gaussian:\n",
    "        image = ndimage.gaussian_filter(image, sigma=sigma)\n",
    "    \n",
    "    # Erst normalisieren\n",
    "    img_mean = image.mean()\n",
    "    img_std = image.std()\n",
    "    if img_std > 0:\n",
    "        norm_image = (image - img_mean) / img_std\n",
    "    else:\n",
    "        print(\"Warning: Standard deviation is zero during normalization.\")\n",
    "        norm_image = image\n",
    "    \n",
    "    return norm_image\n",
    "\n",
    "def illumination_correction_basicpy(images: list, apply_to_image: np.ndarray = None) -> tuple:\n",
    "    \"\"\"\n",
    "    Führt Beleuchtungskorrektur mit BasicPy durch\n",
    "    \n",
    "    Args:\n",
    "        images: Liste von Bildern für die Hintergrundschätzung\n",
    "        apply_to_image: Einzelnes Bild zur Korrektur (optional)\n",
    "    \n",
    "    Returns:\n",
    "        (korrigiertes_bild, flatfield, darkfield) wenn apply_to_image gegeben\n",
    "        (flatfield, darkfield) sonst\n",
    "    \"\"\"\n",
    "    # Konvertiere Liste zu numpy array\n",
    "    if isinstance(images, list):\n",
    "        images_array = np.stack(images, axis=0)\n",
    "    else:\n",
    "        images_array = images\n",
    "    \n",
    "    # Erstelle BaSiC-Objekt\n",
    "    basic = basicpy.BaSiC(get_darkfield=True, smoothness_flatfield=1)\n",
    "    \n",
    "    # Führe BaSiC-Korrektur durch\n",
    "    basic.fit(images_array)\n",
    "    \n",
    "    # Erhalte Flatfield und Darkfield\n",
    "    flatfield = basic.flatfield\n",
    "    darkfield = basic.darkfield\n",
    "    \n",
    "    if apply_to_image is not None:\n",
    "        # Wende Korrektur auf einzelnes Bild an\n",
    "        corrected = basic.transform(apply_to_image[np.newaxis, ...])[0]\n",
    "        return corrected, flatfield, darkfield\n",
    "    \n",
    "    return flatfield, darkfield\n",
    "\n",
    "def normalize_image(image: np.ndarray) -> np.ndarray:\n",
    "    img_mean = image.mean()\n",
    "    img_std = image.std()\n",
    "    if img_std > 0:\n",
    "        norm_image = (image - img_mean) / img_std\n",
    "    else:\n",
    "        print(\"Warning: Standard deviation is zero during normalization.\")\n",
    "        norm_image = image\n",
    "    return norm_image\n",
    "\n",
    "def get_aggregated_pixel_intensity_stats(image: np.ndarray, mask: np.ndarray, channel: str) -> dict:\n",
    "    \n",
    "    stats = {}\n",
    "    masked_pixels = normalize_image(image)[mask > 0]\n",
    "    if masked_pixels.size > 0:\n",
    "        stats[f'mean_intensity_in_mask_{channel}'] = np.mean(masked_pixels)\n",
    "        stats[f'median_intensity_in_mask_{channel}'] = np.median(masked_pixels)\n",
    "    else:\n",
    "        stats[f'mean_intensity_in_mask_{channel}'] = 0\n",
    "        stats[f'median_intensity_in_mask{channel}'] = 0\n",
    "    return stats\n",
    "\n",
    "def load_from_h5_file(file_path: str, count: Union[int, None] = None, features_path: str = None, \n",
    "                      apply_gaussian: bool = True, sigma: float = 1.0,\n",
    "                      apply_illumination_correction: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Lädt Daten aus H5-Datei mit optionaler Gauss-Filterung und Beleuchtungskorrektur\n",
    "    \n",
    "    Args:\n",
    "        file_path: Pfad zur H5-Datei\n",
    "        count: Anzahl der zu ladenden Zellen\n",
    "        features_path: Pfad zum Speichern der Features\n",
    "        apply_gaussian: Ob Gauss-Filter angewendet werden soll\n",
    "        sigma: Standard-Abweichung für Gauss-Filter\n",
    "        apply_illumination_correction: Ob Beleuchtungskorrektur angewendet werden soll\n",
    "    \"\"\"\n",
    "    examples = {}\n",
    "    features = []\n",
    "    \n",
    "    # Sammle Bilder für Beleuchtungskorrektur falls gewünscht\n",
    "    channel_images_for_correction = {}\n",
    "    \n",
    "    with h5py.File(file_path, \"r\") as f:\n",
    "        # Erster Pass: Sammle Bilder für Beleuchtungskorrektur\n",
    "        if apply_illumination_correction:\n",
    "            print(\"Sammle Bilder für Beleuchtungskorrektur...\")\n",
    "            temp_count = 0\n",
    "            for group_name in tqdm(f.keys()):\n",
    "                if temp_count >= min(100, count if count else 100):  # Maximal 100 Bilder für Korrektur\n",
    "                    break\n",
    "                temp_count += 1\n",
    "                grp = f[group_name]\n",
    "                for channel_name, channel_data in grp.items():\n",
    "                    if channel_name == 'seg':  # Überspringe Segmentierung\n",
    "                        continue\n",
    "                    if channel_name not in channel_images_for_correction:\n",
    "                        channel_images_for_correction[channel_name] = []\n",
    "                    \n",
    "                    # Nimm mittleres Bild jedes Kanals\n",
    "                    plane_names = list(channel_data.keys())\n",
    "                    middle_idx = len(plane_names) // 2\n",
    "                    middle_plane = plane_names[middle_idx]\n",
    "                    image = channel_data[middle_plane][()]\n",
    "                    channel_images_for_correction[channel_name].append(image)\n",
    "            \n",
    "            # Berechne Flatfield und Darkfield für jeden Kanal\n",
    "            print(\"Berechne Beleuchtungskorrektur...\")\n",
    "            flatfields = {}\n",
    "            darkfields = {}\n",
    "            for channel_name, images in channel_images_for_correction.items():\n",
    "                if len(images) > 1:\n",
    "                    try:\n",
    "                        flatfield, darkfield = illumination_correction_basicpy(images)\n",
    "                        flatfields[channel_name] = flatfield\n",
    "                        darkfields[channel_name] = darkfield\n",
    "                        print(f\"Beleuchtungskorrektur für Kanal {channel_name} berechnet\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Fehler bei Beleuchtungskorrektur für Kanal {channel_name}: {e}\")\n",
    "                        flatfields[channel_name] = None\n",
    "                        darkfields[channel_name] = None\n",
    "        \n",
    "        # Zweiter Pass: Lade und verarbeite alle Daten\n",
    "        print(\"Lade und verarbeite Zelldaten...\")\n",
    "        group_index = 0\n",
    "        for group_name in tqdm(f.keys()):\n",
    "            if count is not None and group_index >= count:\n",
    "                break\n",
    "            group_index += 1\n",
    "            grp = f[group_name]\n",
    "            examples[group_name] = {}\n",
    "            plane_count = 0\n",
    "            \n",
    "            for channel_name, channel_data in grp.items():\n",
    "                channel_path = f\"{channel_name}\"\n",
    "                examples[group_name][channel_path] = []\n",
    "                plane_count = len(channel_data.values())\n",
    "                \n",
    "                for plane_name, plane_data in channel_data.items():\n",
    "                    image = plane_data[()]\n",
    "                    \n",
    "                    if channel_name != 'seg':\n",
    "                        # Beleuchtungskorrektur anwenden falls verfügbar\n",
    "                        if (apply_illumination_correction and \n",
    "                            channel_name in flatfields and \n",
    "                            flatfields[channel_name] is not None):\n",
    "                            try:\n",
    "                                # Wende BaSiC-Korrektur an\n",
    "                                basic = basicpy.BaSiC(get_darkfield=True)\n",
    "                                basic.flatfield = flatfields[channel_name]\n",
    "                                basic.darkfield = darkfields[channel_name]\n",
    "                                image = basic.transform(image[np.newaxis, ...])[0]\n",
    "                            except Exception as e:\n",
    "                                print(f\"Fehler bei Beleuchtungskorrektur für {group_name}, {channel_name}: {e}\")\n",
    "                        \n",
    "                        # Gauss-Filter und Normalisierung\n",
    "                        processed_img = normalize_and_filter_image(image, apply_gaussian, sigma)\n",
    "                    else:\n",
    "                        processed_img = image\n",
    "                    \n",
    "                    examples[group_name][channel_path].append((plane_name, processed_img))\n",
    "                    \n",
    "            if features_path is not None:\n",
    "                try:\n",
    "                    extracted_nuclei_cell_features = extract_nuclei_cell_features(examples[group_name]['405'][plane_count//2][1], examples[group_name]['seg'][plane_count//2][1], group_name)\n",
    "                    extract_red_channel_stats = get_aggregated_pixel_intensity_stats(examples[group_name]['561'][plane_count//2][1], examples[group_name]['seg'][plane_count//2][1], channel='561')\n",
    "                    extract_green_channel_stats = get_aggregated_pixel_intensity_stats(examples[group_name]['488'][plane_count//2][1], examples[group_name]['seg'][plane_count//2][1], channel='488')\n",
    "                    features_dict = {**extracted_nuclei_cell_features, **extract_red_channel_stats, **extract_green_channel_stats}\n",
    "                    examples[group_name]['features'] = features_dict\n",
    "                    features.append(features_dict)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting features for group {group_name}: {e}\", file=sys.stderr)\n",
    "                    \n",
    "    features_df = pd.DataFrame(features)\n",
    "    if features_path is not None:\n",
    "        file_name_prefix = \"\" if count is None else str(count) + \"_\"\n",
    "        suffix = \"_corrected\" if apply_illumination_correction else \"_gaussian\" if apply_gaussian else \"\"\n",
    "        features_preprocessed_df.to_parquet(file_name_prefix + features_path.replace(\".parquet\", f\"{suffix}.parquet\"))\n",
    "    return examples\n",
    "\n",
    "# Laden der Daten mit Beleuchtungskorrektur und Gauss-Filter\n",
    "examples = load_from_h5_file(\"/mydata/iris/andreas/fucci_3t3_221124_filtered_noNG030JP208.h5\", \n",
    "                           count=2000, features_path=\"cell_features_corrected.parquet\",\n",
    "                           apply_gaussian=True, sigma=1.0,\n",
    "                           apply_illumination_correction=True)\n",
    "features_preprocessed_df = pd.read_parquet(\"2000_cell_features_corrected.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd84ff97",
   "metadata": {},
   "source": [
    "### Source the cell images and extract some features (new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6213d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import H5CellDataset, FeatureExtractor, ImagePreprocessor\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "feature_extractor = FeatureExtractor()\n",
    "image_preprocessor = ImagePreprocessor(apply_gaussian=True, sigma=0.2, apply_illumination_correction=True)\n",
    "\n",
    "dataset_preprocessed = H5CellDataset(\n",
    "    \"/myhome/iris/data/fucci_3t3_221124_filtered_noNG030JP208_with_nuclei_seg.h5\",\n",
    "    feature_extractor=feature_extractor,\n",
    "    preprocessor=image_preprocessor,\n",
    "    return_raw=True,\n",
    "    return_features=True,\n",
    ")\n",
    "dataset_raw = H5CellDataset(\n",
    "    \"/myhome/iris/data/fucci_3t3_221124_filtered_noNG030JP208_with_nuclei_seg.h5\",\n",
    "    feature_extractor=feature_extractor,\n",
    "    preprocessor=None,\n",
    "    return_raw=True,\n",
    "    return_features=True,\n",
    ")\n",
    "indices = np.random.choice(len(dataset_preprocessed), size=1000, replace=False)\n",
    "features_preprocessed_df = dataset_preprocessed.get_features_dataframe(indices=indices)\n",
    "features_raw_df = dataset_raw.get_features_dataframe(indices=indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275dbae9",
   "metadata": {},
   "source": [
    "### Visualize some cell examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "show_n = 2\n",
    "\n",
    "\n",
    "def show_cell_examples(dataset, features_df, show_n=10, channels_to_show=[\"405\", \"488\", \"561\", \"seg\", \"nuclei_seg\", \"bf\"]):\n",
    "    cell_indices = features_df[\"index_cell\"].tolist()\n",
    "    for idx, cell_idx in enumerate(cell_indices):\n",
    "        cell_data = dataset[cell_idx]\n",
    "        cells = cell_data[\"raw_data\"]\n",
    "        cell_name = cell_data[\"cell_name\"]\n",
    "        if idx >= show_n:\n",
    "            break\n",
    "        x_axis_length = len(cells.values()) if channels_to_show is None else len(channels_to_show)\n",
    "        fig, axes = plt.subplots(x_axis_length, 3, figsize=(15, 5*x_axis_length))\n",
    "        fig.suptitle(f\"Cell {cell_name}\")\n",
    "\n",
    "        features_to_show = [\"cell_name\", \"nucleus_area\", \"cell_area\", \"mean_intensity_in_mask_561\", \"mean_intensity_in_mask_488\"]\n",
    "\n",
    "        features_text = \"\\n\".join(\n",
    "            [\n",
    "                f\"{k}: {v:.3f}\" if isinstance(v, float) else f\"{k}: {v}\"\n",
    "                for k, v in features_df[features_to_show].query(f\"cell_name == '{cell_name}'\")\n",
    "                .to_dict(orient=\"records\")[0]\n",
    "                .items()\n",
    "            ]\n",
    "        )\n",
    "        fig.text(0.5, 0.5 * 0.1, features_text, fontsize=10, ha=\"center\")\n",
    "        channel_idx = 0\n",
    "        for channel, imgs in cells.items():\n",
    "            if channels_to_show is not None and channel not in channels_to_show:\n",
    "                continue\n",
    "            if channel == \"features\":\n",
    "                continue\n",
    "            for i, (plane_name, img) in enumerate(imgs):\n",
    "                if x_axis_length == 1:\n",
    "                    ax = axes[i]\n",
    "                else:\n",
    "                    ax = axes[channel_idx, i]\n",
    "                if type(img) != np.ndarray:\n",
    "                    import pdb; pdb.set_trace()\n",
    "                    print(f\"Skipping non-array image for cell {cell_name}, channel {channel}, plane {plane_name}\")\n",
    "                    continue\n",
    "                ax.imshow(\n",
    "                    img,\n",
    "                    cmap=\"gray\",\n",
    "                    aspect=\"auto\",\n",
    "                )\n",
    "                if channel != \"seg\" and channel != \"nuclei_seg\":\n",
    "                    ax.contour(cells[\"seg\"][i][1], colors=\"r\")\n",
    "                    ax.contour(cells[\"nuclei_seg\"][i][1], colors=\"g\")\n",
    "                ax.axis(\"off\")\n",
    "                ax.set_title(f\"{channel} - Plane {plane_name}\")\n",
    "                \n",
    "            channel_idx += 1\n",
    "        plt.show()\n",
    "\n",
    "print(\"Preprocessed Data Examples:\")\n",
    "show_cell_examples(dataset_preprocessed, features_preprocessed_df, show_n=show_n)\n",
    "print(\"Raw Data Examples:\")\n",
    "show_cell_examples(dataset_raw, features_raw_df, show_n=show_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2b2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_features = features_preprocessed_df[features_preprocessed_df[\"cell_nucleus_area_ratio\"] > 1]\n",
    "print(f\"Number of cells with nucleus area larger than cell area: {len(outlier_features)} out of {len(features_preprocessed_df)}\")\n",
    "\n",
    "shown_examples = 0\n",
    "for idx,feature in features_preprocessed_df.iterrows():\n",
    "    if shown_examples >= 10:\n",
    "        break\n",
    "    if feature[\"cell_nucleus_area_ratio\"] > 1:\n",
    "        shown_examples += 1\n",
    "        show_cell_examples(dataset_preprocessed, features_df=features_preprocessed_df.iloc[[idx]], show_n=20, channels_to_show=[\"bf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d3fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D scatter plot of mean intensities for both channels\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "color_feature = \"cell_area\"  # Change this to any other feature if needed\n",
    "scatter = ax.scatter(\n",
    "    features_preprocessed_df['mean_intensity_in_mask_488'],\n",
    "    features_preprocessed_df['mean_intensity_in_mask_561'],\n",
    "    c=features_preprocessed_df[color_feature],\n",
    "    cmap='Blues',\n",
    "    alpha=1.0,\n",
    "    s=50\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Mean Intensity in Mask - Channel 488 (Green: G1 phase)', fontsize=12)\n",
    "ax.set_ylabel('Mean Intensity in Mask - Channel 561 (Red:  S/G2/M phase)', fontsize=12)\n",
    "ax.set_title('Mean Intensity Comparison: Channel 488 vs Channel 561', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add colorbar\n",
    "plt.colorbar(scatter, ax=ax, label=color_feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Channel 488 - Mean: {features_preprocessed_df['mean_intensity_in_mask_488'].mean():.3f}, Std: {features_preprocessed_df['mean_intensity_in_mask_488'].std():.3f}\")\n",
    "print(f\"Channel 561 - Mean: {features_preprocessed_df['mean_intensity_in_mask_561'].mean():.3f}, Std: {features_preprocessed_df['mean_intensity_in_mask_561'].std():.3f}\")\n",
    "print(f\"Correlation: {features_preprocessed_df[['mean_intensity_in_mask_488', 'mean_intensity_in_mask_561']].corr().iloc[0, 1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e198a45",
   "metadata": {},
   "source": [
    "### Reduce dimension and visualize clusters from features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# Select numerical features for t-SNE\n",
    "feature_cols = [col for col in features_preprocessed_df.columns if (col.startswith('cell_') or col.startswith('nucleus_')) and col != 'cell_name'] \n",
    "X = features_preprocessed_df[feature_cols].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Run t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "# Add t-SNE coordinates to dataframe\n",
    "tsne_features_df = features_preprocessed_df.copy()\n",
    "tsne_features_df['tsne_1'] = X_tsne[:, 0]\n",
    "tsne_features_df['tsne_2'] = X_tsne[:, 1]\n",
    "\n",
    "fig = px.scatter(\n",
    "    tsne_features_df,\n",
    "    x=\"tsne_1\",\n",
    "    y=\"tsne_2\",\n",
    "    color=\"mean_intensity_in_mask_488\",\n",
    "    hover_data=[\"cell_name\"],\n",
    "    title=\"t-SNE: 488nm Channel (Green)\",\n",
    "    color_continuous_scale=\"Greens\",\n",
    ")\n",
    "fig.show()\n",
    "# Create separate scatter plots for each channel with their respective colors\n",
    "fig = px.scatter(\n",
    "    tsne_features_df,\n",
    "    x=\"tsne_1\",\n",
    "    y=\"tsne_2\",\n",
    "    color=\"mean_intensity_in_mask_561\",\n",
    "    hover_data=[\"cell_name\"],\n",
    "    title=\"t-SNE: 561nm Channel (Red)\",\n",
    "    color_continuous_scale=\"Reds\",\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Create an RGB color based on the two channel intensities\n",
    "\n",
    "# Normalize intensities to [0, 1] for color mapping\n",
    "norm_561 = (tsne_features_df['mean_intensity_in_mask_561'] / \n",
    "    tsne_features_df['mean_intensity_in_mask_561'].max()\n",
    ")\n",
    "norm_488 = (tsne_features_df['mean_intensity_in_mask_488'] / \n",
    "    tsne_features_df['mean_intensity_in_mask_488'].max()\n",
    ")\n",
    "\n",
    "# Map 561 to red, 488 to green (assuming these are the respective channels)\n",
    "rgb_colors = np.stack([norm_561, norm_488, np.zeros_like(norm_561)], axis=1)\n",
    "rgb_colors = [f\"rgb({int(r*255)},{int(g*255)},{int(b*255)})\" for r, g, b in rgb_colors]\n",
    "fig = px.scatter(\n",
    "    tsne_features_df,\n",
    "    x=\"tsne_1\",\n",
    "    y=\"tsne_2\",\n",
    "    color=rgb_colors,\n",
    "    hover_data=[\"cell_name\"],\n",
    "    title=\"t-SNE: True Color by Channel Intensities\",\n",
    ")\n",
    "fig.update_traces(marker=dict(size=10, line=dict(width=0)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52a90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get indices for different fluorescence cases\n",
    "def get_example_indices(norm_561, norm_488, n=3):\n",
    "    # Very red: high 561, low 488\n",
    "    red_idx = ((norm_561 > 0.8) & (norm_488 < 0.2)).nlargest(n).index\n",
    "    # Very green: high 488, low 561\n",
    "    green_idx = ((norm_488 > 0.8) & (norm_561 < 0.2)).nlargest(n).index\n",
    "    # Mixed: both high\n",
    "    mixed_idx = ((norm_561 > 0.6) & (norm_488 > 0.6)).nlargest(n).index\n",
    "    # Both low\n",
    "    low_idx = ((norm_561 < 0.2) & (norm_488 < 0.2)).nlargest(n).index\n",
    "    return {\n",
    "        \"Very Red\": red_idx,\n",
    "        \"Very Green\": green_idx,\n",
    "        \"Mixed\": mixed_idx,\n",
    "        \"Low Both\": low_idx,\n",
    "    }\n",
    "\n",
    "example_indices = get_example_indices(norm_561, norm_488, n=3)\n",
    "\n",
    "for label, idxs in example_indices.items():\n",
    "    print(f\"\\n{label} examples:\")\n",
    "    for i in idxs:\n",
    "        print(f\"  Cell index: {i}, norm_561={norm_561[i]:.2f}, norm_488={norm_488[i]:.2f}\")\n",
    "        show_cell_examples(dataset_preprocessed, features_df=features_preprocessed_df.iloc[[i]], show_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Select features to correlate with mean intensities\n",
    "corr_features = feature_cols + ['mean_intensity_in_mask_561', 'mean_intensity_in_mask_488']\n",
    "corr_df = features_preprocessed_df[corr_features]\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = corr_df.corr()\n",
    "\n",
    "# Visualize correlation with mean_intensity_in_mask_561 and mean_intensity_in_mask_488\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.heatmap(\n",
    "    corr_matrix[['mean_intensity_in_mask_561', 'mean_intensity_in_mask_488']].loc[feature_cols],\n",
    "    annot=True, cmap='coolwarm', vmin=-1, vmax=1\n",
    ")\n",
    "plt.title('Correlation of Features with Channel Mean Intensities')\n",
    "plt.show()\n",
    "\n",
    "# Find top 4 features most correlated (absolute value) with either channel\n",
    "top_features = (\n",
    "    corr_matrix[['mean_intensity_in_mask_561', 'mean_intensity_in_mask_488']]\n",
    "    .loc[feature_cols]\n",
    "    .abs()\n",
    "    .max(axis=1)\n",
    "    .sort_values(ascending=False)\n",
    "    .head(6)\n",
    "    .index.tolist()\n",
    ")\n",
    "\n",
    "# Plot scatter plots for each top feature vs both mean intensities\n",
    "fig, axes = plt.subplots(3, 2, figsize=(28, 20))\n",
    "for i, feat in enumerate(top_features):\n",
    "    ax = axes.flat[i]\n",
    "    sns.scatterplot(\n",
    "        x=features_preprocessed_df[feat],\n",
    "        y=features_preprocessed_df['mean_intensity_in_mask_561'],\n",
    "        label='561', alpha=0.6, ax=ax\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        x=features_preprocessed_df[feat],\n",
    "        y=features_preprocessed_df['mean_intensity_in_mask_488'],\n",
    "        label='488', alpha=0.6, ax=ax\n",
    "    )\n",
    "    ax.set_xlabel(feat)\n",
    "    ax.set_ylabel('Mean Intensity')\n",
    "    ax.set_title(f\"{feat} vs Channel Mean Intensities\")\n",
    "    ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e136af",
   "metadata": {},
   "source": [
    "### Get outliers and visualize some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dcb506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def get_outlier_cells(features_df, feature_cols, contamination=0.05):\n",
    "    outlier_model = IsolationForest(contamination=contamination, random_state=42)\n",
    "    outlier_features = features_df[feature_cols]\n",
    "    outlier_pred = outlier_model.fit_predict(outlier_features)\n",
    "    outlier_idx = outlier_pred == -1\n",
    "    print(f\"Anzahl Outlier: {outlier_idx.sum()}\")\n",
    "    return features_preprocessed_df[outlier_idx].index.tolist()\n",
    "\n",
    "def show_bf_and_405_images_for_outliers(examples, outlier_idx, max_n=10):\n",
    "    \"\"\"\n",
    "    Zeigt sowohl BF- als auch 405-Bilder für Outlier-Zellen\n",
    "    \"\"\"\n",
    "    for i, idx in enumerate(outlier_idx):\n",
    "        if i >= max_n:\n",
    "            break\n",
    "        show_cell_examples(examples, features_df=features_preprocessed_df.iloc[[idx]], show_n=1)\n",
    "\n",
    "\n",
    "# Outlier-Erkennung basierend auf verschiedenen Features\n",
    "feature_cols = [\n",
    "    col\n",
    "    for col in features_preprocessed_df.columns\n",
    "    if not col.endswith(\"488\") and not col.endswith(\"561\")\n",
    "]\n",
    "\n",
    "outlier_idx = get_outlier_cells(features_preprocessed_df, feature_cols, contamination=0.05)\n",
    "show_bf_and_405_images_for_outliers(dataset_preprocessed, outlier_idx, max_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9117115",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
